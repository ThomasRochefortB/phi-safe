{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import safe\n",
    "\n",
    "# Load the trained model and tokenizer\n",
    "checkpoint_path = \".saved_model/phi1_5-safmol_0528/checkpoint-1600\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Define generation parameters\n",
    "generation_args = {\n",
    "    \"max_length\": 128,  # Adjust the maximum length of the generated sequence\n",
    "    \"num_return_sequences\": 10,  # Number of sequences to generate\n",
    "    \"temperature\": 1.0,  # Sampling temperature\n",
    "    \"do_sample\": True,  # Use sampling instead of greedy decoding\n",
    "}\n",
    "\n",
    "# Generate a sequence without a prompt\n",
    "input_ids = torch.tensor([[tokenizer.pad_token_id]])  # Use the pad token ID as a dummy input\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_sequences = model.generate(input_ids, **generation_args)\n",
    "\n",
    "# Decode the generated sequence\n",
    "\n",
    "def decode_generated_sequences(tokenizer, generated_sequences):\n",
    "    decoded_texts = []\n",
    "    for sequence in generated_sequences:\n",
    "        decoded_text = tokenizer.decode(sequence, skip_special_tokens=True)\n",
    "        decoded_texts.append(decoded_text)\n",
    "    return decoded_texts\n",
    "decoded_texts = decode_generated_sequences(tokenizer, generated_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated SAFE strings:\n",
      "String 1: C3ccc(F)sc1nc5ccn(F)c(F)ccc(F)cc1F.C5(F)(S34)C1=OCCO94.C914.C9CC(F)(F)F(F[P(F)(F)F(F[)(F[)F1[)C16C=C1[O-].C76.CC04.n15CCCC\n",
      "String 2: C45C3n2nACCC2=N12.C=O.c13ccccc1.C88=O.[C@H]12[C@H]8C26.N16CCCCC5CC1.C5(C9=O)C3C(=O)c2ccccn2[1.C9[C(=O)C17.C38.C319C.C17CC.C9(=O\n",
      "String 3: C7.C763.C1C(C)C.c16ccc3nc16.C13P(Cl)c2ccccn5n12[Cl3c1ccc(Cl)cc14.c14CN(=N)C=CCC=3c2cnccc2n1.C83.c18ccc8ccc15.O35[CCO16.c16\n",
      "String 4: C8CC4.c14cccnc1.c15cnnn6c1.O63.C36CN5CC4.[C@@H]7=O.[C@@H]7(O)(O64.c2cccc(CO2)c3ccccc3)CO.C3(C)(C)C.C21CC1C1C1C1C[n\n",
      "String 5: Cc1ccc8nc2nc14.C58=O.N=C(O)(C)CN=2.C3(F)F.N32.C4.C14CCC=5.C=5CC1.N/C4(F)C(F)F(=O)C(F)F1CCn(C)3[CC1.C3(F)F(F)F1CC11O.\n",
      "String 6: Cncn3n1ncc2ccCl8c8Cc2c1.[C@H]18[nH]Oc1[nH]c7c(F)cccc(F)cc18.[C@H]17[C@(C)C[nH]5[nH]5OC\\52.C67.C39.O36.C19CCN(C1)CCN4CCC3.[C@H](\n",
      "String 7: C7=nc2c([C@@H]3c3ccc%10cc2cccc5ccc2o1.c15cc8cc(Cl)c(N)cc9n1.n19[C@@H](C)C(C)C/C(C)CC=CC3C.C==c2cccccc2c1C26=O=C9C(C)C=C3C\n",
      "String 8: CN=C4O.c14ccc(N)cc1.C56.c15cccc(F)c1cc[nH2c1O.[12C(O)C9O1.C9(F)C8.O36.C(F)(F)(F)FC12.S(F)(F)F7.C71.C81.CC14.C14.C\n",
      "String 9: 3CC7=c1cnc4nc4nc2c6nc(8)cc21CC#3CCCCN5(n)cc2cccnnc1.N15CCOC8C(=[N+](C)C(=N)C(C)(C)C4c2s[nH]9C)C-].C3C9(C)C.4c6c(F)c2[C@H]-]C.C4CC\n",
      "String 10: 70m]1CCO%13.C74.c14ccc(F)c(F)cc1.n16cc(F)c(F)c(F)cc1FCCC12.C85.N18C(F)(F)F(F)FC1CC1#N=c[+]oc2c6c+]cc3cc4c+]c5n2cc6+]coc2c3ccc[\n",
      "Unique lengths of generated sequences: {128}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate formatted texts\n",
    "formatted_texts = [f\"String {i+1}: {text}\" for i, text in enumerate(decoded_texts)]\n",
    "\n",
    "# Print the generated SAFE strings\n",
    "print(\"Generated SAFE strings:\\n\" + \"\\n\".join(formatted_texts))\n",
    "\n",
    "# Create a set to store the unique lengths\n",
    "unique_lengths = set(len(text) for text in generated_sequences)\n",
    "\n",
    "# Print the unique lengths\n",
    "print(\"Unique lengths of generated sequences:\", unique_lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safemol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
